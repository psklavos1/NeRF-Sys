{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8fb0ec",
   "metadata": {},
   "source": [
    "\n",
    "# Task Sampler — Visual Sanity Check\n",
    "\n",
    "Edit the CONFIG below, then run all cells.  \n",
    "This will:\n",
    "1. Load your **ImageMetadata** via `dataset.get_image_metadata(...)`.\n",
    "2. Build a **RamRaysDataset** (if its imports resolve), otherwise warn.\n",
    "3. Use **RegionTaskSampler** to sample tasks.\n",
    "4. **Display the RGB images** selected for support and query for the first few tasks.\n",
    "\n",
    "> If `RamRaysDataset` fails to import because of `nerfs.ray_sampling`, the notebook will stop and tell you how to fix your Python path. No redefinitions are in this notebook; we import everything from your files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d73b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# CONFIG \n",
    "# =====================\n",
    "from pathlib import Path\n",
    "# Imports\n",
    "import sys, os, math\n",
    "# Move cwd up one level (from project_dir/jupyter -> project_dir)\n",
    "ROOT = Path(__file__).resolve().parents[1] if \"__file__\" in globals() else Path(os.getcwd()).parents[0]\n",
    "if os.getcwd() != \"/mnt/nas_drive/psklavos/crexdata/MCLNF-FDA\":\n",
    "    os.chdir(ROOT)\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "print(\"CWD set to:\", os.getcwd())\n",
    "\n",
    "\n",
    "# Sampler/task params\n",
    "NUM_TASKS_TO_SHOW = 4\n",
    "S = 3; Q = 2\n",
    "REGION_ID = 1\n",
    "RAYS_SUPPORT = 1000\n",
    "RAYS_QUERY = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c08d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from data.dataset import get_image_metadata, cap_metadata\n",
    "\n",
    "DATA_PATH = \"data/drz/out/prepared\"  # e.g., \"/data/out/partner_germany_site_01\"\n",
    "SCALE = .25            # 1.0 => original resolution\n",
    "MASK_DIR = Path(DATA_PATH) / 'masks' /'g22_kmeans_bm110_ss13'/ str(REGION_ID)         # or a subdir name under DATA_PATH/masks\n",
    "# Load metadata (train & val)\n",
    "train_md, val_md = get_image_metadata(DATA_PATH, SCALE, mask_dir=MASK_DIR)\n",
    "\n",
    "print(f\"Loaded metadata: train={len(train_md)} images, val={len(val_md)} images\")\n",
    "print(f\"Example image path: {train_md[0].image_path if len(train_md)>0 else val_md[0].image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b947cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.ram_rays_dataset import RamRaysDataset\n",
    "\n",
    "# Build RamRaysDataset if possible\n",
    "MAX_IMAGES = 250\n",
    "train_md = cap_metadata(train_md,MAX_IMAGES)\n",
    "kwargs = dict(center_pixels=True, device=torch.device(\"cpu\"))\n",
    "train_ds = RamRaysDataset(metadata_items=train_md, **kwargs)\n",
    "\n",
    "use_ds = train_ds if train_ds is not None else None\n",
    "print(f\"Using dataset with {len(use_ds):,} rays from {use_ds._num_images} images.\")\n",
    "\n",
    "use_ds._rays[1000]\n",
    "use_ds._img_indices[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.task_dataset import TaskDataset\n",
    "RAYS_SUPPORT = 4000\n",
    "RAYS_QUERY   = 2000\n",
    "MIN_RAYS     = 100_000     # skip if region has fewer than this many rays\n",
    "# IMAGE_CAP    = 0.40     # max fraction per image in each split (set None to disable)\n",
    "# STEPS_PER_EPOCH = 1000  # or None for infinite stream\n",
    "\n",
    "task_ds = TaskDataset(\n",
    "    ram_ds=use_ds,\n",
    "    cell_id=REGION_ID,\n",
    "    S_target=RAYS_SUPPORT,\n",
    "    Q_target=RAYS_QUERY,\n",
    "    image_cap= .4,\n",
    "    min_rays_cell=MIN_RAYS,\n",
    "    assignment_checkpoint= .7,\n",
    "    debug=True,\n",
    "    routing_policy='dda',\n",
    "    cells=(1,7,7)\n",
    ")\n",
    "\n",
    "\n",
    "# Or, if you want a DataLoader (recommended; matches your MultiLoader pattern):\n",
    "from torch.utils.data import DataLoader\n",
    "task_loader = DataLoader(\n",
    "    task_ds,\n",
    "    batch_size=3,              # one Task per batch entry\n",
    "    num_workers=0,             # keep 0 unless your buffers are immutable/thread-safe\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=lambda xs: xs,  # keep list[Task]\n",
    ")\n",
    "\n",
    "# Example: get one task and plot like before\n",
    "batch = next(iter(task_loader))\n",
    "task = batch[0]\n",
    "for task in batch:\n",
    "    print(\"Region:\", task.cell_id, \"S:\", int(task.metrics[\"S\"]), \"Q:\", int(task.metrics[\"Q\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615adac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TASKS_TO_LOAD = 10\n",
    "NUM_TASKS_TO_SHOW = 1\n",
    "\n",
    "# Helper to show images given list of image indices (img_ids stored by the dataset)\n",
    "def show_image(path, title=None, max_size=256):\n",
    "    im = Image.open(path).convert(\"RGB\")\n",
    "    w, h = im.size\n",
    "    scale = min(1.0, max_size / max(w, h))\n",
    "    if scale < 1.0:\n",
    "        im = im.resize((int(w*scale), int(h*scale)), Image.LANCZOS)\n",
    "    plt.imshow(im); plt.axis(\"off\")\n",
    "    if title: plt.title(title)\n",
    "\n",
    "# Build a map from image_id -> metadata (to get image file path)\n",
    "# The dataset assigns unified image indices across train+val in get_image_metadata\n",
    "id2md = {md.image_index: md for md in (train_md + val_md)}\n",
    "\n",
    "# ---- SAMPLE TASKS (from TaskDataset) ----\n",
    "tasks = []\n",
    "it = iter(task_ds)  # task_ds is your TaskDataset instance for this region\n",
    "for _ in range(NUM_TASKS_TO_LOAD):\n",
    "    try:\n",
    "        tasks.append(next(it))\n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "print(f\"Collected {len(tasks)} tasks; visualizing first {min(NUM_TASKS_TO_SHOW, len(tasks))}.\")\n",
    "\n",
    "# ---- VISUALIZE ----\n",
    "for t_idx, task in enumerate(tasks[:NUM_TASKS_TO_SHOW], 1):\n",
    "    # pull unique image ids from tensors (works with 'img_indices' or 'img_ids')\n",
    "    sup_tensor = task.support.get(\"img_indices\", task.support.get(\"img_ids\"))\n",
    "    qry_tensor = task.query.get(\"img_indices\", task.query.get(\"img_ids\"))\n",
    "\n",
    "    sup_ids = torch.unique(sup_tensor).tolist() if sup_tensor is not None else []\n",
    "    qry_ids = torch.unique(qry_tensor).tolist() if qry_tensor is not None else []\n",
    "\n",
    "    # Grid layout: columns is the max of both sets; rows=2 only if we have queries\n",
    "    cols = max(1, len(sup_ids), len(qry_ids))\n",
    "    rows = 2 if len(qry_ids) > 0 else 1\n",
    "\n",
    "    plt.figure(figsize=(3.5 * cols, 3.5 * rows))\n",
    "\n",
    "    # --- Support row (row 1) ---\n",
    "    for i, img_id in enumerate(sup_ids[:cols]):\n",
    "        ax_idx = i + 1  # 1-based index\n",
    "        plt.subplot(rows, cols, ax_idx)\n",
    "        md = id2md[img_id]\n",
    "        show_image(md.image_path, title=f\"Support img_id={img_id}\")\n",
    "\n",
    "    # --- Query row (row 2) ---\n",
    "    if rows == 2:\n",
    "        for j, img_id in enumerate(qry_ids[:cols]):\n",
    "            ax_idx = cols + j + 1\n",
    "            plt.subplot(rows, cols, ax_idx)\n",
    "            md = id2md[img_id]  # FIX: set inside this loop\n",
    "            show_image(md.image_path, title=f\"Query img_id={img_id}\")\n",
    "\n",
    "    S = int(task.metrics.get(\"S\", len(task.support.get(\"rays\", []))))\n",
    "    Q = int(task.metrics.get(\"Q\", len(task.query.get(\"rays\", []))))\n",
    "    plt.suptitle(f\"Task {t_idx}: S={S} Q={Q}\", y=0.99)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if task.warnings:\n",
    "        print(\"Warnings:\")\n",
    "        for warning in task.warnings:\n",
    "            print(f\"Task {t_idx}: {warning}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaaebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "# --- colors (support/query only) ---\n",
    "COLOR_SUP  = np.array([  0, 255, 255], np.uint8)   # cyan\n",
    "COLOR_QRY  = np.array([255, 255, 0], np.uint8)   # pink\n",
    "CELL_EDGE  = (0.70, 0.00, 0.70)                    # magenta-like, in 0..1 floats\n",
    "\n",
    "ALPHA_SUP  = 0.75\n",
    "ALPHA_QRY  = 0.65\n",
    "\n",
    "DILATE_RADIUS       = 1\n",
    "MAX_RAYS_PER_IMAGE  = 200_000\n",
    "NUM_TASKS_TO_SHOW   = 10 \n",
    "\n",
    "# ----------------- helpers -----------------\n",
    "\n",
    "def _dilate(mask, ys, xs, R):\n",
    "    if R <= 0:\n",
    "        mask[ys, xs] = True; return\n",
    "    H, W = mask.shape\n",
    "    for dy in range(-R, R+1):\n",
    "        yy = ys + dy\n",
    "        v_y = (yy >= 0) & (yy < H)\n",
    "        if not np.any(v_y): continue\n",
    "        yy = yy[v_y]; xs_v = xs[v_y]\n",
    "        for dx in range(-R, R+1):\n",
    "            xx = xs_v + dx\n",
    "            v_x = (xx >= 0) & (xx < W)\n",
    "            if np.any(v_x):\n",
    "                mask[yy[v_x], xx[v_x]] = True\n",
    "\n",
    "def project_dirs_to_pixels(md, d_world):\n",
    "    \"\"\"Project world directions onto image pixels (handles +/-Z forward).\"\"\"\n",
    "    c2w = md.c2w.to(d_world.device).float()\n",
    "    R = c2w[:3,:3]; Rt = R.t()\n",
    "    d_cam = (Rt @ d_world.T).T\n",
    "\n",
    "    fx, fy, cx, cy = [float(x) for x in md.intrinsics]\n",
    "    W, H = int(md.W), int(md.H)\n",
    "    if max(fx, fy, cx, cy) <= 2.5:\n",
    "        fx *= W; fy *= H; cx *= W; cy *= H\n",
    "\n",
    "    def proj(sign):\n",
    "        z = d_cam[:,2]\n",
    "        if sign < 0:\n",
    "            valid = z < -1e-6; denom = -z\n",
    "        else:\n",
    "            valid = z >  1e-6; denom =  z\n",
    "        if not valid.any(): return np.empty(0), np.empty(0)\n",
    "        dc = d_cam[valid]\n",
    "        u = fx * (dc[:,0]/denom[valid]) + cx\n",
    "        v = fy * (dc[:,1]/denom[valid]) + cy\n",
    "        inb = (u >= 0) & (u < W) & (v >= 0) & (v < H)\n",
    "        return u[inb].cpu().numpy(), v[inb].cpu().numpy()\n",
    "\n",
    "    u1,v1 = proj(-1.0); u2,v2 = proj(+1.0)\n",
    "    return (u1,v1) if u1.size >= u2.size else (u2,v2)\n",
    "\n",
    "def build_mask_from_indices(md, idx_tensor, use_ds):\n",
    "    \"\"\"Indices -> project to pixels -> boolean mask (dedup + optional dilate).\"\"\"\n",
    "    W, H = int(md.W), int(md.H)\n",
    "    mask = np.zeros((H, W), dtype=bool)\n",
    "    if idx_tensor is None or idx_tensor.numel() == 0:\n",
    "        return mask, 0\n",
    "    sel = idx_tensor\n",
    "    if sel.numel() > MAX_RAYS_PER_IMAGE:\n",
    "        perm = torch.randperm(sel.numel(), device=sel.device)[:MAX_RAYS_PER_IMAGE]\n",
    "        sel = sel[perm]\n",
    "    d_world = use_ds._rays[sel, 3:6].float()\n",
    "    u, v = project_dirs_to_pixels(md, d_world)\n",
    "    if u.size == 0: return mask, 0\n",
    "    xs = np.rint(np.clip(u, 0, W-1)).astype(np.int32)\n",
    "    ys = np.rint(np.clip(v, 0, H-1)).astype(np.int32)\n",
    "    if xs.size > 0:\n",
    "        uniq = np.unique(np.stack([ys, xs], 1), axis=0)\n",
    "        ys, xs = uniq[:,0], uniq[:,1]\n",
    "        _dilate(mask, ys, xs, DILATE_RADIUS)\n",
    "    return mask, xs.size\n",
    "\n",
    "def overlay_masks(md, sup_mask, qry_mask):\n",
    "    \"\"\"Blend two masks into the image (no overlap color; we will assert/clip overlaps).\"\"\"\n",
    "    base = Image.open(md.image_path).convert(\"RGB\")\n",
    "    H, W = sup_mask.shape\n",
    "    if base.size != (W, H):\n",
    "        base = base.resize((W, H), Image.LANCZOS)\n",
    "    out = np.array(base, dtype=np.uint8)\n",
    "\n",
    "    # enforce pixel-level disjointness (visual); if you prefer assertion-only, drop this line\n",
    "    qry_mask = np.logical_and(qry_mask, ~sup_mask)\n",
    "\n",
    "    def blend(mask2d, color, alpha):\n",
    "        if not np.any(mask2d): return\n",
    "        pix = out[mask2d]\n",
    "        out[mask2d] = ((1 - alpha) * pix + alpha * color).astype(np.uint8)\n",
    "\n",
    "    blend(sup_mask, COLOR_SUP, ALPHA_SUP)\n",
    "    blend(qry_mask, COLOR_QRY, ALPHA_QRY)\n",
    "    return out\n",
    "\n",
    "def _get_w2c(md):\n",
    "    \"\"\"Prefer w2c if present; otherwise invert c2w.\"\"\"\n",
    "    if hasattr(md, \"w2c\"):\n",
    "        return md.w2c.cpu().numpy().astype(np.float64)\n",
    "    c2w = md.c2w.cpu().numpy().astype(np.float64)\n",
    "    R, t = c2w[:3,:3], c2w[:3,3]\n",
    "    w2c = np.eye(4, dtype=np.float64)\n",
    "    w2c[:3,:3] = R.T\n",
    "    w2c[:3, 3] = -R.T @ t\n",
    "    return w2c\n",
    "\n",
    "def project_point(md, Pw, eps=1e-9):\n",
    "    w2c = _get_w2c(md)\n",
    "    Pc = (w2c[:3,:3] @ Pw) + w2c[:3,3]\n",
    "    fx, fy, cx, cy = map(float, md.intrinsics)\n",
    "    W, H = int(md.W), int(md.H)\n",
    "    if max(fx, fy, cx, cy) <= 2.5:\n",
    "        fx *= W; fy *= H; cx *= W; cy *= H\n",
    "    z = float(Pc[2])\n",
    "    # Always compute u,v with a safe denom; mark visibility separately.\n",
    "    denom = z if abs(z) > eps else (eps if z >= 0 else -eps)\n",
    "    u = fx * (Pc[0] / denom) + cx\n",
    "    v = fy * (Pc[1] / denom) + cy\n",
    "    visible = (z > eps) and (0 <= u < W) and (0 <= v < H)\n",
    "    return (u, v, visible)\n",
    "\n",
    "\n",
    "\n",
    "def _clip_2d_to_rect(p0, p1, W, H):\n",
    "    # Cohen–Sutherland on [0,W]x[0,H]; returns (ok, q0, q1)\n",
    "    LEFT, RIGHT, BOTTOM, TOP = 1, 2, 4, 8\n",
    "    def code(x,y):\n",
    "        c=0\n",
    "        if x<0: c|=LEFT\n",
    "        elif x>W: c|=RIGHT\n",
    "        if y<0: c|=TOP\n",
    "        elif y>H: c|=BOTTOM\n",
    "        return c\n",
    "    x0,y0 = p0; x1,y1 = p1\n",
    "    c0, c1 = code(x0,y0), code(x1,y1)\n",
    "    while True:\n",
    "        if not (c0|c1):  # both inside\n",
    "            return True, (x0,y0), (x1,y1)\n",
    "        if c0 & c1:      # both outside same half-space\n",
    "            return False, None, None\n",
    "        c_out = c0 or c1\n",
    "        if c_out & TOP:\n",
    "            x = x0+(x1-x0)*(0-y0)/(y1-y0); y = 0\n",
    "        elif c_out & BOTTOM:\n",
    "            x = x0+(x1-x0)*(H-y0)/(y1-y0); y = H\n",
    "        elif c_out & RIGHT:\n",
    "            y = y0+(y1-y0)*(W-x0)/(x1-x0); x = W\n",
    "        else: # LEFT\n",
    "            y = y0+(y1-y0)*(0-x0)/(x1-x0); x = 0\n",
    "        if c_out == c0:\n",
    "            x0,y0 = x,y; c0 = code(x0,y0)\n",
    "        else:\n",
    "            x1,y1 = x,y; c1 = code(x1,y1)\n",
    "\n",
    "def draw_cell_edges(ax, md, cell_bounds, color=CELL_EDGE, lw=3.0):\n",
    "    lo = cell_bounds[0].detach().cpu().numpy()\n",
    "    hi = cell_bounds[1].detach().cpu().numpy()\n",
    "    C = np.array([\n",
    "        [lo[0], lo[1], lo[2]], [hi[0], lo[1], lo[2]],\n",
    "        [hi[0], hi[1], lo[2]], [lo[0], hi[1], lo[2]],\n",
    "        [lo[0], lo[1], hi[2]], [hi[0], lo[1], hi[2]],\n",
    "        [hi[0], hi[1], hi[2]], [lo[0], hi[1], hi[2]],\n",
    "    ], dtype=np.float64)\n",
    "    E = [(0,1),(1,2),(2,3),(3,0),(4,5),(5,6),(6,7),(7,4),(0,4),(1,5),(2,6),(3,7)]\n",
    "    W, H = int(md.W), int(md.H)\n",
    "    for a, b in E:\n",
    "        ua, va, oka = project_point(md, C[a])\n",
    "        ub, vb, okb = project_point(md, C[b])\n",
    "        # require points to be in front of the camera (your project_point already checks Pc[2] > 0)\n",
    "        if not oka and not okb:\n",
    "            continue\n",
    "        ok, (x0,y0), (x1,y1) = _clip_2d_to_rect((ua,va), (ub,vb), W-1, H-1)\n",
    "        if not ok:\n",
    "            continue\n",
    "        ax.plot([x0, x1], [y0, y1], '-', color=color, linewidth=lw, alpha=1.0, zorder=3,\n",
    "                path_effects=[pe.Stroke(linewidth=lw+1.5, foreground='k'), pe.Normal()])\n",
    "\n",
    "# ----------------- visualize + assert -----------------\n",
    "\n",
    "for t_idx, task in enumerate(tasks[:NUM_TASKS_TO_SHOW], 1):\n",
    "    # --- (A) hard assertions for ray-level disjointness ---\n",
    "    sup_idx = task.support.get(\"idx\")\n",
    "    qry_idx = task.query.get(\"idx\")\n",
    "    assert sup_idx is not None and qry_idx is not None, \"Task must carry global 'idx' for both splits.\"\n",
    "    # no duplicates inside a split\n",
    "    assert sup_idx.numel() == torch.unique(sup_idx).numel(), \"Duplicates inside support!\"\n",
    "    assert qry_idx.numel() == torch.unique(qry_idx).numel(), \"Duplicates inside query!\"\n",
    "    A = torch.unique(task.support[\"idx\"])\n",
    "    B = torch.unique(task.query[\"idx\"])\n",
    "    AB = torch.unique(torch.cat([A, B]))\n",
    "    assert AB.numel() == A.numel() + B.numel(), \"S/Q intersect at ray level!\"\n",
    "    \n",
    "    \n",
    "    # --- group selected global ray indices per image ---\n",
    "    sup_img = task.support[\"img_indices\"]\n",
    "    qry_img = task.query[\"img_indices\"]\n",
    "    sup_map, qry_map = {}, {}\n",
    "    for img_id in torch.unique(sup_img).tolist():\n",
    "        sup_map[img_id] = sup_idx[(sup_img == img_id)]\n",
    "    for img_id in torch.unique(qry_img).tolist():\n",
    "        qry_map[img_id] = qry_idx[(qry_img == img_id)]\n",
    "\n",
    "    img_ids = sorted(set(sup_map.keys()) | set(qry_map.keys()))\n",
    "    cols = min(4, max(1, len(img_ids)))\n",
    "    rows = int(np.ceil(len(img_ids) / cols))\n",
    "    plt.figure(figsize=(4.6*cols, 4.6*rows))\n",
    "\n",
    "    for i, img_id in enumerate(img_ids, 1):\n",
    "        ax = plt.subplot(rows, cols, i)\n",
    "        md = id2md[img_id]\n",
    "\n",
    "        # build masks\n",
    "        sup_mask, _ = build_mask_from_indices(md, sup_map.get(img_id), use_ds)\n",
    "        qry_mask, _ = build_mask_from_indices(md, qry_map.get(img_id), use_ds)\n",
    "\n",
    "\n",
    "        # overlay\n",
    "        rgb = overlay_masks(md, sup_mask, qry_mask)\n",
    "        ax.imshow(rgb); ax.axis(\"off\")\n",
    "        ax.set_xlim(0, int(md.W)); ax.set_ylim(int(md.H), 0)  # lock view\n",
    "\n",
    "        # draw the micro-cell box (task.bounds must be the cell AABB [2,3])\n",
    "        # draw_cell_edges(ax, md, task.bounds)\n",
    "\n",
    "        ax.set_title(f\"Task {t_idx} | img_id={img_id}\", fontsize=9)\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"Task {t_idx}: region={task.cell_id}  cell={task.cell_id}  \"\n",
    "        f\"S={int(task.metrics['S'])}  Q={int(task.metrics['Q'])}  \"\n",
    "        f\"cell_rays={int(task.metrics['total_cell'])}\",\n",
    "        y=0.99, fontsize=10\n",
    "    )\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaaebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Task visualizer (full)\n",
    "# =========================\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "# ----------------- config -----------------\n",
    "NUM_TASKS_TO_SHOW   = 10\n",
    "\n",
    "# colors\n",
    "COLOR_SUP  = np.array([  0, 255, 255], np.uint8)  # cyan\n",
    "COLOR_QRY  = np.array([255, 255,   0], np.uint8)  # yellow\n",
    "CELL_FACE  = (0.70, 0.00, 0.70)                   # magenta-ish\n",
    "CELL_EDGE  = (0.35, 0.00, 0.35)\n",
    "\n",
    "ALPHA_SUP  = 0.80\n",
    "ALPHA_QRY  = 0.70\n",
    "CELL_ALPHA = 0.22\n",
    "\n",
    "# ray subsampling for speed (per-image)\n",
    "MAX_RAYS_PER_IMAGE = 200_000\n",
    "\n",
    "# geometry threshold (what “counts” as inside the cell)\n",
    "MIN_OVERLAP_FRAC = 0.03   # >= 3% of cell diagonal\n",
    "MIN_OVERLAP_ABS  = 0.0    # or absolute distance in scene units\n",
    "\n",
    "# ----------------- low-level helpers -----------------\n",
    "def _get_w2c(md):\n",
    "    \"\"\"Prefer w2c if present; otherwise invert c2w.\"\"\"\n",
    "    if hasattr(md, \"w2c\"):\n",
    "        return md.w2c.detach().cpu().numpy().astype(np.float64)\n",
    "    c2w = md.c2w.detach().cpu().numpy().astype(np.float64)\n",
    "    R, t = c2w[:3,:3], c2w[:3,3]\n",
    "    w2c = np.eye(4, dtype=np.float64)\n",
    "    w2c[:3,:3] = R.T\n",
    "    w2c[:3, 3] = -R.T @ t\n",
    "    return w2c\n",
    "\n",
    "def project_point(md, Pw, eps=1e-9):\n",
    "    \"\"\"Project a single world point to pixel (u,v), return (u,v,visible).\"\"\"\n",
    "    w2c = _get_w2c(md)\n",
    "    Pc = (w2c[:3,:3] @ Pw) + w2c[:3,3]\n",
    "    fx, fy, cx, cy = map(float, md.intrinsics)\n",
    "    W, H = int(md.W), int(md.H)\n",
    "    if max(fx, fy, cx, cy) <= 2.5:  # normalized intrinsics → pixels\n",
    "        fx *= W; fy *= H; cx *= W; cy *= H\n",
    "    z = float(Pc[2])\n",
    "    denom = z if abs(z) > eps else (eps if z >= 0 else -eps)\n",
    "    u = fx * (Pc[0] / denom) + cx\n",
    "    v = fy * (Pc[1] / denom) + cy\n",
    "    visible = (z > eps) and (0 <= u < W) and (0 <= v < H)\n",
    "    return (u, v, visible)\n",
    "\n",
    "# ----------------- cell projection (filled faces) -----------------\n",
    "_CELL_EDGES = [(0,1),(1,2),(2,3),(3,0),(4,5),(5,6),(6,7),(7,4),(0,4),(1,5),(2,6),(3,7)]\n",
    "_CELL_FACES = [\n",
    "    (0,1,2,3),  # z=lo\n",
    "    (4,5,6,7),  # z=hi\n",
    "    (0,1,5,4),  # y=lo\n",
    "    (2,3,7,6),  # y=hi\n",
    "    (1,2,6,5),  # x=hi\n",
    "    (0,3,7,4),  # x=lo\n",
    "]\n",
    "\n",
    "def _cell_corners_numpy(cell_bounds):\n",
    "    lo = cell_bounds[0].detach().cpu().numpy()\n",
    "    hi = cell_bounds[1].detach().cpu().numpy()\n",
    "    return np.array([\n",
    "        [lo[0], lo[1], lo[2]], [hi[0], lo[1], lo[2]],\n",
    "        [hi[0], hi[1], lo[2]], [lo[0], hi[1], lo[2]],\n",
    "        [lo[0], lo[1], hi[2]], [hi[0], lo[1], hi[2]],\n",
    "        [hi[0], hi[1], hi[2]], [lo[0], hi[1], hi[2]],\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "def _clip_2d_to_rect(poly, W, H):\n",
    "    \"\"\"Sutherland–Hodgman clip of polygon 'poly' against [0,W-1]x[0,H-1].\"\"\"\n",
    "    def clip(polygon, edge):\n",
    "        out = []\n",
    "        if not polygon: return out\n",
    "        if edge == 'left':\n",
    "            inside = lambda P: P[0] >= 0\n",
    "            I = lambda A,B: (0, A[1] + (B[1]-A[1])*(0-A[0])/(B[0]-A[0] + 1e-20))\n",
    "        elif edge == 'right':\n",
    "            xw = W-1\n",
    "            inside = lambda P: P[0] <= xw\n",
    "            I = lambda A,B: (xw, A[1] + (B[1]-A[1])*(xw-A[0])/(B[0]-A[0] + 1e-20))\n",
    "        elif edge == 'top':\n",
    "            inside = lambda P: P[1] >= 0\n",
    "            I = lambda A,B: (A[0] + (B[0]-A[0])*(0-A[1])/(B[1]-A[1] + 1e-20), 0)\n",
    "        else:  # bottom\n",
    "            yh = H-1\n",
    "            inside = lambda P: P[1] <= yh\n",
    "            I = lambda A,B: (A[0] + (B[0]-A[0])*(yh-A[1])/(B[1]-A[1] + 1e-20), yh)\n",
    "        S = polygon[-1]\n",
    "        for E in polygon:\n",
    "            if inside(E):\n",
    "                if inside(S): out.append(E)\n",
    "                else: out.append(I(S,E)); out.append(E)\n",
    "            else:\n",
    "                if inside(S): out.append(I(S,E))\n",
    "            S = E\n",
    "        return out\n",
    "    for e in ('left','right','top','bottom'):\n",
    "        poly = clip(poly, e)\n",
    "        if not poly: break\n",
    "    return poly\n",
    "\n",
    "def _project_cell_faces(md, cell_bounds):\n",
    "    C = _cell_corners_numpy(cell_bounds)\n",
    "    W, H = int(md.W), int(md.H)\n",
    "    # project all corners (even if behind)\n",
    "    UV = []\n",
    "    for Pw in C:\n",
    "        u, v, _ = project_point(md, Pw)\n",
    "        UV.append((u, v))\n",
    "    UV = np.array(UV, float)\n",
    "    # build & clip 6 faces\n",
    "    polys = []\n",
    "    for f in _CELL_FACES:\n",
    "        poly = [(UV[i,0], UV[i,1]) for i in f]\n",
    "        poly = _clip_2d_to_rect(poly, W, H)\n",
    "        if len(poly) >= 3:\n",
    "            polys.append(poly)\n",
    "    return polys\n",
    "\n",
    "def draw_cell_filled(ax, md, cell_bounds, face_alpha=CELL_ALPHA, edge_alpha=0.9,\n",
    "                     face_color=CELL_FACE, edge_color=CELL_EDGE, lw=1.5):\n",
    "    polys = _project_cell_faces(md, cell_bounds)\n",
    "    for poly in polys:\n",
    "        ax.add_patch(mpatches.Polygon(poly, closed=True,\n",
    "                                      facecolor=face_color, edgecolor=edge_color,\n",
    "                                      linewidth=lw, alpha=face_alpha, zorder=3))\n",
    "    # draw edges stronger\n",
    "    C = _cell_corners_numpy(cell_bounds)\n",
    "    for (i,j) in _CELL_EDGES:\n",
    "        u0,v0,_ = project_point(md, C[i]); u1,v1,_ = project_point(md, C[j])\n",
    "        seg = _clip_2d_to_rect([(u0,v0),(u1,v1)], int(md.W), int(md.H))\n",
    "        if len(seg) >= 2:\n",
    "            xs, ys = zip(*seg[:2])\n",
    "            ax.plot(xs, ys, '-', color=edge_color, linewidth=lw, alpha=edge_alpha, zorder=4,\n",
    "                    path_effects=[pe.Stroke(linewidth=lw+1.2, foreground='k'), pe.Normal()])\n",
    "\n",
    "# ----------------- in-cell midpoint computation -----------------\n",
    "def _ray_cell_segment_np(rays_np, cell_bounds_np):\n",
    "    \"\"\"Compute [t_entry, t_exit] of ray vs AABB; returns (hit, t0, t1).\"\"\"\n",
    "    o = rays_np[:, :3]; d = rays_np[:, 3:6]\n",
    "    near = rays_np[:, 6]; far = rays_np[:, 7]\n",
    "    lo, hi = cell_bounds_np[0], cell_bounds_np[1]\n",
    "    invd = 1.0 / np.where(np.abs(d) < 1e-12, np.sign(d)*1e-12, d)\n",
    "    t0 = (lo - o) * invd\n",
    "    t1 = (hi - o) * invd\n",
    "    tmin = np.minimum(t0, t1).max(axis=1)\n",
    "    tmax = np.maximum(t0, t1).min(axis=1)\n",
    "    t_entry = np.maximum.reduce([tmin, near, np.zeros_like(near)])\n",
    "    t_exit  = np.minimum(tmax, far)\n",
    "    hit = t_exit > t_entry\n",
    "    return hit, t_entry, t_exit\n",
    "\n",
    "def incell_midpoints_world(rays_sel, cell_bounds):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "      P (M,3) world midpoints,\n",
    "      keep_mask over K,\n",
    "      overlap_lengths (only for kept rays)\n",
    "    \"\"\"\n",
    "    if rays_sel is None or rays_sel.numel() == 0:\n",
    "        return np.empty((0,3)), np.zeros((0,), bool), np.empty((0,))\n",
    "    r = rays_sel.detach().cpu().numpy()\n",
    "    cb = cell_bounds.detach().cpu().numpy()\n",
    "    hit, t0, t1 = _ray_cell_segment_np(r, cb)\n",
    "    cell_diag = np.linalg.norm(cb[1] - cb[0])\n",
    "    min_len = max(MIN_OVERLAP_ABS, MIN_OVERLAP_FRAC * cell_diag)\n",
    "    L = (t1 - t0)\n",
    "    keep = hit & (L >= min_len)\n",
    "    if not keep.any():\n",
    "        return np.empty((0,3)), keep, np.empty((0,))\n",
    "    tm = 0.5 * (t0[keep] + t1[keep])\n",
    "    P = r[keep, :3] + r[keep, 3:6] * tm[:, None]\n",
    "    return P, keep, L[keep]\n",
    "\n",
    "def project_points_uv(md, P):\n",
    "    \"\"\"Project array of world points (M,3) to integer pixels (N,2).\"\"\"\n",
    "    if P.size == 0: return np.empty((0,2), int)\n",
    "    out = []\n",
    "    for Pw in P:\n",
    "        u, v, vis = project_point(md, Pw)\n",
    "        if vis: out.append((int(round(u)), int(round(v))))\n",
    "    if not out: return np.empty((0,2), int)\n",
    "    return np.array(out, int)\n",
    "\n",
    "# ----------------- plotting + assertions -----------------\n",
    "def assert_ray_disjoint_and_incell(sup_idx, qry_idx, cell_bounds):\n",
    "    \"\"\"Hard checks: S/Q disjointness + all rays overlap cell by threshold.\"\"\"\n",
    "    # disjointness\n",
    "    su = torch.unique(sup_idx); qu = torch.unique(qry_idx)\n",
    "    AB = torch.unique(torch.cat([su, qu]))\n",
    "    assert AB.numel() == su.numel() + qu.numel(), \"S/Q intersect at ray level!\"\n",
    "\n",
    "    # geometry\n",
    "    def _check(idx, name):\n",
    "        r = use_ds._rays[idx]\n",
    "        _, keep, _ = incell_midpoints_world(r, cell_bounds)\n",
    "        if not np.all(keep):\n",
    "            bad = int((~keep).sum())\n",
    "            raise AssertionError(f\"{bad} {name} rays do not overlap cell by \"\n",
    "                                 f\"min_len=max({MIN_OVERLAP_ABS}, {MIN_OVERLAP_FRAC}*diag).\")\n",
    "    _check(sup_idx, \"support\"); _check(qry_idx, \"query\")\n",
    "\n",
    "def build_img_to_indices_map(img_tensor, idx_tensor):\n",
    "    m = {}\n",
    "    for img_id in torch.unique(img_tensor).tolist():\n",
    "        sel = idx_tensor[(img_tensor == img_id)]\n",
    "        # optional speed: downsample a lot\n",
    "        if sel.numel() > MAX_RAYS_PER_IMAGE:\n",
    "            perm = torch.randperm(sel.numel(), device=sel.device)[:MAX_RAYS_PER_IMAGE]\n",
    "            sel = sel[perm]\n",
    "        m[img_id] = sel\n",
    "    return m\n",
    "\n",
    "def print_task_summary(task, sup_map, qry_map, Ls, Lq):\n",
    "    sup_ids = sorted(sup_map.keys()); qry_ids = sorted(qry_map.keys())\n",
    "    print(f\"Task cell={task.cell_id} | S={int(task.metrics['S'])} Q={int(task.metrics['Q'])} | \"\n",
    "          f\"S_imgs={len(sup_ids)} Q_imgs={len(qry_ids)} | disjoint_ok={bool(task.metrics.get('image_disjoint_ok',1.0))}\")\n",
    "    # per-image counts\n",
    "    def counts(m): return {k:int(m[k].numel()) for k in sorted(m)}\n",
    "    print(\"  support imgs & counts:\", counts(sup_map))\n",
    "    print(\"  query   imgs & counts:\", counts(qry_map))\n",
    "    # overlap stats\n",
    "    fmt = lambda a: f\"min={a.min():.4g} mean={a.mean():.4g} max={a.max():.4g}\" if a.size else \"n/a\"\n",
    "    print(\"  overlap S:\", fmt(Ls), \"| overlap Q:\", fmt(Lq))\n",
    "    if task.warnings:\n",
    "        for w in task.warnings:\n",
    "            print(\"  warning:\", w)\n",
    "\n",
    "# ----------------- MAIN LOOP -----------------\n",
    "for t_idx, task in enumerate(tasks[:NUM_TASKS_TO_SHOW], 1):\n",
    "    sup_idx = task.support[\"idx\"]; qry_idx = task.query[\"idx\"]\n",
    "    assert sup_idx.numel() == torch.unique(sup_idx).numel(), \"Duplicates in support!\"\n",
    "    assert qry_idx.numel() == torch.unique(qry_idx).numel(), \"Duplicates in query!\"\n",
    "    # assert_ray_disjoint_and_incell(sup_idx, qry_idx, task.bounds)\n",
    "\n",
    "    sup_img = task.support[\"img_indices\"]; qry_img = task.query[\"img_indices\"]\n",
    "    sup_map = build_img_to_indices_map(sup_img, sup_idx)\n",
    "    qry_map = build_img_to_indices_map(qry_img, qry_idx)\n",
    "\n",
    "    # precompute overlap lengths (for printing)\n",
    "    rS = use_ds._rays[sup_idx]; _, _, Ls = incell_midpoints_world(rS, task.bounds)\n",
    "    rQ = use_ds._rays[qry_idx]; _, _, Lq = incell_midpoints_world(rQ, task.bounds)\n",
    "    print_task_summary(task, sup_map, qry_map, Ls, Lq)\n",
    "\n",
    "    # figure layout\n",
    "    img_ids = sorted(set(sup_map.keys()) | set(qry_map.keys()))\n",
    "    cols = min(4, max(1, len(img_ids)))\n",
    "    rows = int(np.ceil(len(img_ids) / cols))\n",
    "    plt.figure(figsize=(4.8*cols, 4.8*rows))\n",
    "\n",
    "    for i, img_id in enumerate(img_ids, 1):\n",
    "        ax = plt.subplot(rows, cols, i)\n",
    "        md = id2md[img_id]\n",
    "        base = Image.open(md.image_path).convert(\"RGB\")\n",
    "        ax.imshow(base); ax.axis(\"off\")\n",
    "        ax.set_xlim(0, int(md.W)); ax.set_ylim(int(md.H), 0)\n",
    "\n",
    "        # SUPPORT points (in-cell midpoints)\n",
    "        if img_id in sup_map:\n",
    "            P, _, _ = incell_midpoints_world(use_ds._rays[sup_map[img_id]], task.bounds)\n",
    "            uv = project_points_uv(md, P)\n",
    "            if uv.size:\n",
    "                ax.scatter(uv[:,0], uv[:,1], s=6, marker='o', linewidths=0,\n",
    "                           c=[(0,1,1)], alpha=ALPHA_SUP, zorder=5)\n",
    "\n",
    "        # QUERY points (in-cell midpoints)\n",
    "        if img_id in qry_map:\n",
    "            P, _, _ = incell_midpoints_world(use_ds._rays[qry_map[img_id]], task.bounds)\n",
    "            uv = project_points_uv(md, P)\n",
    "            if uv.size:\n",
    "                ax.scatter(uv[:,0], uv[:,1], s=6, marker='o', linewidths=0,\n",
    "                           c=[(1,1,0)], alpha=ALPHA_QRY, zorder=5)\n",
    "\n",
    "        # draw filled voxel (under points)\n",
    "        draw_cell_filled(ax, md, task.bounds, face_alpha=CELL_ALPHA)\n",
    "\n",
    "        ax.set_title(f\"Task {t_idx} | img_id={img_id}\", fontsize=9)\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"Task {t_idx}: region={task.cid}  cell={task.cell_id}  \"\n",
    "        f\"S={int(task.metrics['S'])}  Q={int(task.metrics['Q'])}  \"\n",
    "        f\"cell_rays={int(task.metrics['total_cell'])}\",\n",
    "        y=0.99, fontsize=10\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mclnf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
